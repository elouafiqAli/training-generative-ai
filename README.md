# Generative AI Foundations

The purpose of this training is to initiate SQLI collaborators to Generative AI Through foundations.

## Why? a Foundations Training?

The AI breakthroughs are accelerating, and learning the foundations and the inner working of GenAI Systems is key to understand, keep track of progress, and then contribute to it.

There are plenty of training and material available in the Internet, that introduces GenAI from a Usage standpoint, such as Prompting, Function Call, Finetuning.

Such practices will not be covered as the resources in the Internet are widely available. Collaborators can access them, such as [Deep Learning AI](https://deeplearning.ai/), and [Google Cloud Generative AI Course](https://www.cloudskillsboost.google/course_templates/536/video/518258)

Moreover, with the fast pace change of the market available tools, any tooling training would be obsolete by the next year as new tools are introduced.

Furthermore, advanced deployments of Generative AI, such as Performance Optimization, Error Improvement, or Reasoning and Planning would remain inaccessible, unless one understands the fundamentals.

This is why the purpose of this training is teach this _building blocks of modern AI and Machine Learning_ techniques, and their progress from _Descriminative to Generative_.

## Where is this approach inspired from?

This approach is inspired from various efforts, from industry to academia, to introduce foundational concepts.

Notably the following trainings and courses have inspired it, and would be based on their material:
- [Andrej Karpathy's](https://karpathy.ai/), founding Member of OpenAI, former Director of AI at Tesla, trainings and source code, [building micrograd](https://www.youtube.com/watch?v=VMj-3S1tku0), [building makemore](https://www.youtube.com/watch?v=PaCmpygFfXo&t=1107s), and [building GPT from scratch](https://www.youtube.com/watch?v=kCc8FmEb1nY)
- [Jeremy Howard's Series](https://course.fast.ai/Lessons/part2.html), Chief Scientist at Kaggle, [Practical Deep Learning for Coders](https://course.fast.ai/)
- [Alan Edelman](https://math.mit.edu/~edelman/), and co-author of Julia Programming Language, [Matrix Calculus for Machine Learning](https://ocw.mit.edu/courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023)
- [Center for Research on Foundation Models @Stanford](https://crfm.stanford.edu/people.html) foundations of AI course at Stanford,  [Artificial Intelligence Principles and Techniques](https://www.youtube.com/playlist?list=PLoROMvodv4rOca_Ovz1DvdtWuz8BfSWL2)
- [Peter Norvig](https://en.wikipedia.org/wiki/Peter_Norvig) former Director of Search Quality at Google, and co-author of best seller AI: a Modern Approach Udacity's [Artificial Intelligence Nanodegree Program](https://www.udacity.com/course/ai-artificial-intelligence-nanodegree--nd898)
